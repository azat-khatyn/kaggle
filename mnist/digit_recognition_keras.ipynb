{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Recognizer Challenge\n",
    "\n",
    "This notebook contains a solution for the Digit Recognizer Kaggle Challenge.https://www.kaggle.com/c/digit-recognizer\n",
    "\n",
    "#### About the challenge:\n",
    "\n",
    "\n",
    "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
    "\n",
    "In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.\n",
    "\n",
    "\n",
    "#### About this notebook:\n",
    "\n",
    "This notebook will use Keras Sequential Model with five hidden convolutional layers using ReLU activation functions as well as MaxPool and Flatten layers and a SoftMax activation function in the output layer. \n",
    "\n",
    "The model will be trained using ImageDataGenerator module, which will help to augment the data. \n",
    "\n",
    "A simple grid search for hyperparameter tuning will be implemented.\n",
    "\n",
    "The code will be executed in a AWS SageMaker notebook using GPU.\n",
    "\n",
    "#### About the results:\n",
    "\n",
    "The simple appproach presented in this notebook showed a result corresponding to top 12 % of submissions on leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_val, Y_val, optimizer, loss, epochs, batch_size):\n",
    "    \n",
    "    model = prepare_model()\n",
    "    \n",
    "    model.compile(optimizer = optimizer ,loss = loss, metrics=[\"accuracy\"])\n",
    "       \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False, \n",
    "        rotation_range=10, \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False)\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size)\n",
    "\n",
    "    return model, history.history['val_acc'][epochs-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(predictions):\n",
    "    predictions = np.argmax(predictions,axis = 1)\n",
    "    predictions = pd.Series(predictions,name=\"Label\")\n",
    "    submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predictions],axis = 1)\n",
    "    submission.to_csv(\"submission_cnn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['SGD', 'RMSProp', 'Adagrad']\n",
    "losses = ['categorical_crossentropy', 'categorical_hinge', 'mean_squared_error']\n",
    "batch_sizes = [32, 64]\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_score = 0\n",
    "best_optimizer = None\n",
    "best_loss = 0\n",
    "best_epochs = 0\n",
    "best_batch_size = 0\n",
    "hyperparameters = list(itertools.product(optimizers,losses, batch_sizes))\n",
    "i = 0\n",
    "for optimizer, loss, batch_size in hyperparameters:\n",
    "    i += 1\n",
    "    print('====================================================')\n",
    "    print('=================Iteration %2d of %d=================' % (i , len(hyperparameters)))\n",
    "    print('=================Training with optimizer=%s, loss=%s, epochs=%d, batch_size=%d================' % (optimizer, loss, epochs, batch_size))\n",
    "    print('====================================================')\n",
    "    model, score = train_model(X_train, Y_train, X_val, Y_val, optimizer, loss, epochs, batch_size)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_optimizer = optimizer\n",
    "        best_loss = loss\n",
    "        best_epochs = epochs\n",
    "        best_batch_size = batch_size\n",
    "\n",
    "print('=======================================')\n",
    "print('=================Done!=================')\n",
    "print('Best model: optimizer=%s, loss=%s, epochs=%d, batch_size=%d, val_acc=%f' % (best_optimizer, best_loss, best_epochs, best_batch_size, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "===============Training with optimizer=RMSProp, loss=categorical_crossentropy, epochs=20, batch_size=64==============\n",
      "====================================================\n",
      "Epoch 1/20\n",
      " - 16s - loss: 0.3738 - acc: 0.8797 - val_loss: 0.0664 - val_acc: 0.9800\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1194 - acc: 0.9650 - val_loss: 0.0535 - val_acc: 0.9850\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0907 - acc: 0.9732 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.0832 - acc: 0.9762 - val_loss: 0.0356 - val_acc: 0.9876\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0771 - acc: 0.9785 - val_loss: 0.0256 - val_acc: 0.9929\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0717 - acc: 0.9796 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0683 - acc: 0.9813 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0679 - acc: 0.9808 - val_loss: 0.0278 - val_acc: 0.9921\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0700 - acc: 0.9799 - val_loss: 0.0426 - val_acc: 0.9886\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0691 - acc: 0.9819 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0702 - acc: 0.9813 - val_loss: 0.0290 - val_acc: 0.9905\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0716 - acc: 0.9808 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0703 - acc: 0.9817 - val_loss: 0.0287 - val_acc: 0.9933\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0739 - acc: 0.9814 - val_loss: 0.0349 - val_acc: 0.9895\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0754 - acc: 0.9803 - val_loss: 0.0384 - val_acc: 0.9879\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0724 - acc: 0.9816 - val_loss: 0.0584 - val_acc: 0.9864\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0773 - acc: 0.9803 - val_loss: 0.0580 - val_acc: 0.9914\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0775 - acc: 0.9810 - val_loss: 0.0434 - val_acc: 0.9917\n",
      "Epoch 19/20\n",
      " - 12s - loss: 0.0809 - acc: 0.9807 - val_loss: 0.0460 - val_acc: 0.9910\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0835 - acc: 0.9797 - val_loss: 0.0392 - val_acc: 0.9900\n",
      "Best model retrained: optimizer=RMSProp, loss=categorical_crossentropy, epochs=20, batch_size=64, val_acc=0.990000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "print('====================================================')\n",
    "print('===============Training with optimizer=%s, loss=%s, epochs=%d, batch_size=%d==============' % (best_optimizer, best_loss, epochs, best_batch_size))\n",
    "print('====================================================')\n",
    "model, score = train_model(X_train, Y_train, X_val, Y_val, best_optimizer, best_loss, epochs, best_batch_size)\n",
    "print('Best model retrained: optimizer=%s, loss=%s, epochs=%d, batch_size=%d, val_acc=%f' % (best_optimizer, best_loss, epochs, best_batch_size, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
