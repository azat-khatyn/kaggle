{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_val, Y_val, optimizer, loss, epochs, batch_size):\n",
    "    \n",
    "    model = prepare_model()\n",
    "    \n",
    "    model.compile(optimizer = optimizer ,loss = loss, metrics=[\"accuracy\"])\n",
    "       \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False, \n",
    "        zca_whitening=False, \n",
    "        rotation_range=10, \n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=False,  \n",
    "        vertical_flip=False)\n",
    "\n",
    "    datagen.fit(X_train)\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size)\n",
    "\n",
    "    return model, history.history['val_acc'][epochs-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(predictions):\n",
    "    predictions = np.argmax(predictions,axis = 1)\n",
    "    predictions = pd.Series(predictions,name=\"Label\")\n",
    "    submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),predictions],axis = 1)\n",
    "    submission.to_csv(\"submission_cnn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = ['SGD', 'RMSProp', 'Adagrad']\n",
    "losses = ['categorical_crossentropy', 'categorical_hinge', 'mean_squared_error']\n",
    "batch_sizes = [32, 64]\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "=================Iteration  1 of 18=================\n",
      "=================Training with optimizer=SGD, loss=categorical_crossentropy, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 15s - loss: 1.3603 - acc: 0.5264 - val_loss: 0.2084 - val_acc: 0.9379\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.4202 - acc: 0.8666 - val_loss: 0.1172 - val_acc: 0.9660\n",
      "Epoch 3/10\n",
      " - 14s - loss: 0.2826 - acc: 0.9126 - val_loss: 0.0852 - val_acc: 0.9743\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.2243 - acc: 0.9316 - val_loss: 0.0723 - val_acc: 0.9779\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.1950 - acc: 0.9395 - val_loss: 0.0687 - val_acc: 0.9793\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.1730 - acc: 0.9471 - val_loss: 0.0606 - val_acc: 0.9805\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.1587 - acc: 0.9514 - val_loss: 0.0535 - val_acc: 0.9860\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.1440 - acc: 0.9567 - val_loss: 0.0478 - val_acc: 0.9860\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.1345 - acc: 0.9594 - val_loss: 0.0439 - val_acc: 0.9864\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.1238 - acc: 0.9609 - val_loss: 0.0415 - val_acc: 0.9867\n",
      "====================================================\n",
      "=================Iteration  2 of 18=================\n",
      "=================Training with optimizer=SGD, loss=categorical_crossentropy, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 13s - loss: 1.8767 - acc: 0.3327 - val_loss: 0.5949 - val_acc: 0.8617\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.7598 - acc: 0.7542 - val_loss: 0.1815 - val_acc: 0.9448\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.4202 - acc: 0.8677 - val_loss: 0.1290 - val_acc: 0.9602\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.3239 - acc: 0.9007 - val_loss: 0.1087 - val_acc: 0.9652\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.2678 - acc: 0.9186 - val_loss: 0.1014 - val_acc: 0.9688\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.2358 - acc: 0.9288 - val_loss: 0.0858 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.2178 - acc: 0.9354 - val_loss: 0.0780 - val_acc: 0.9755\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.1946 - acc: 0.9408 - val_loss: 0.0689 - val_acc: 0.9800\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.1796 - acc: 0.9454 - val_loss: 0.0653 - val_acc: 0.9795\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.1718 - acc: 0.9478 - val_loss: 0.0616 - val_acc: 0.9810\n",
      "====================================================\n",
      "=================Iteration  3 of 18=================\n",
      "=================Training with optimizer=SGD, loss=categorical_hinge, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 16s - loss: 1.0015 - acc: 0.1256 - val_loss: 1.0000 - val_acc: 0.0893\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1101 - val_loss: 1.0000 - val_acc: 0.0912\n",
      "Epoch 3/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1054 - val_loss: 1.0000 - val_acc: 0.1098\n",
      "Epoch 4/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1038 - val_loss: 1.0000 - val_acc: 0.1155\n",
      "Epoch 5/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1025 - val_loss: 1.0000 - val_acc: 0.1164\n",
      "Epoch 6/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1022 - val_loss: 1.0000 - val_acc: 0.1174\n",
      "Epoch 7/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1013 - val_loss: 1.0000 - val_acc: 0.1062\n",
      "Epoch 8/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1030 - val_loss: 1.0000 - val_acc: 0.0976\n",
      "Epoch 9/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1022 - val_loss: 1.0000 - val_acc: 0.0883\n",
      "Epoch 10/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1052 - val_loss: 1.0000 - val_acc: 0.0886\n",
      "====================================================\n",
      "=================Iteration  4 of 18=================\n",
      "=================Training with optimizer=SGD, loss=categorical_hinge, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 14s - loss: 1.0030 - acc: 0.1234 - val_loss: 1.0002 - val_acc: 0.2181\n",
      "Epoch 2/10\n",
      " - 11s - loss: 1.0002 - acc: 0.1321 - val_loss: 1.0000 - val_acc: 0.0881\n",
      "Epoch 3/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1088 - val_loss: 1.0000 - val_acc: 0.1074\n",
      "Epoch 4/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1028 - val_loss: 1.0000 - val_acc: 0.0995\n",
      "Epoch 5/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1038 - val_loss: 1.0000 - val_acc: 0.1160\n",
      "Epoch 6/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1020 - val_loss: 1.0000 - val_acc: 0.0988\n",
      "Epoch 7/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1011 - val_loss: 1.0000 - val_acc: 0.0990\n",
      "Epoch 8/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1041 - val_loss: 1.0000 - val_acc: 0.1181\n",
      "Epoch 9/10\n",
      " - 11s - loss: 1.0000 - acc: 0.0997 - val_loss: 1.0000 - val_acc: 0.0888\n",
      "Epoch 10/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1011 - val_loss: 1.0000 - val_acc: 0.1024\n",
      "====================================================\n",
      "=================Iteration  5 of 18=================\n",
      "=================Training with optimizer=SGD, loss=mean_squared_error, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.0900 - acc: 0.1071 - val_loss: 0.0899 - val_acc: 0.1090\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.0899 - acc: 0.1129 - val_loss: 0.0898 - val_acc: 0.1679\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0898 - acc: 0.1330 - val_loss: 0.0896 - val_acc: 0.2733\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.0897 - acc: 0.1463 - val_loss: 0.0894 - val_acc: 0.3188\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0896 - acc: 0.1609 - val_loss: 0.0892 - val_acc: 0.3386\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0894 - acc: 0.1755 - val_loss: 0.0889 - val_acc: 0.3367\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0890 - acc: 0.1872 - val_loss: 0.0882 - val_acc: 0.3269\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.0885 - acc: 0.1973 - val_loss: 0.0870 - val_acc: 0.3221\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0873 - acc: 0.2172 - val_loss: 0.0839 - val_acc: 0.4224\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0848 - acc: 0.2655 - val_loss: 0.0767 - val_acc: 0.5726\n",
      "====================================================\n",
      "=================Iteration  6 of 18=================\n",
      "=================Training with optimizer=SGD, loss=mean_squared_error, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 14s - loss: 0.0900 - acc: 0.0954 - val_loss: 0.0900 - val_acc: 0.0424\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.0900 - acc: 0.0980 - val_loss: 0.0899 - val_acc: 0.0502\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0899 - acc: 0.1089 - val_loss: 0.0899 - val_acc: 0.0729\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0899 - acc: 0.1137 - val_loss: 0.0898 - val_acc: 0.1071\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0899 - acc: 0.1180 - val_loss: 0.0898 - val_acc: 0.1402\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0898 - acc: 0.1275 - val_loss: 0.0897 - val_acc: 0.1702\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0898 - acc: 0.1305 - val_loss: 0.0896 - val_acc: 0.1938\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0897 - acc: 0.1353 - val_loss: 0.0895 - val_acc: 0.2038\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0896 - acc: 0.1452 - val_loss: 0.0894 - val_acc: 0.2121\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0896 - acc: 0.1488 - val_loss: 0.0893 - val_acc: 0.2117\n",
      "====================================================\n",
      "=================Iteration  7 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=categorical_crossentropy, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 17s - loss: 0.3429 - acc: 0.8900 - val_loss: 0.0456 - val_acc: 0.9852\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.1221 - acc: 0.9652 - val_loss: 0.0369 - val_acc: 0.9898\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.1046 - acc: 0.9699 - val_loss: 0.0497 - val_acc: 0.9840\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.0952 - acc: 0.9732 - val_loss: 0.0296 - val_acc: 0.9910\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0977 - acc: 0.9733 - val_loss: 0.0277 - val_acc: 0.9917\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0967 - acc: 0.9738 - val_loss: 0.0551 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0983 - acc: 0.9734 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.1017 - acc: 0.9738 - val_loss: 0.0360 - val_acc: 0.9907\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.1084 - acc: 0.9718 - val_loss: 0.0560 - val_acc: 0.9869\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.1116 - acc: 0.9715 - val_loss: 0.0603 - val_acc: 0.9860\n",
      "====================================================\n",
      "=================Iteration  8 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=categorical_crossentropy, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 14s - loss: 0.3748 - acc: 0.8799 - val_loss: 0.0713 - val_acc: 0.9798\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.1272 - acc: 0.9614 - val_loss: 0.0493 - val_acc: 0.9855\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0968 - acc: 0.9708 - val_loss: 0.0445 - val_acc: 0.9879\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0835 - acc: 0.9752 - val_loss: 0.0338 - val_acc: 0.9910\n",
      "Epoch 5/10\n",
      " - 12s - loss: 0.0746 - acc: 0.9787 - val_loss: 0.0355 - val_acc: 0.9914\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0718 - acc: 0.9800 - val_loss: 0.0384 - val_acc: 0.9905\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0677 - acc: 0.9810 - val_loss: 0.0300 - val_acc: 0.9917\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0705 - acc: 0.9807 - val_loss: 0.0238 - val_acc: 0.9931\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0684 - acc: 0.9813 - val_loss: 0.0270 - val_acc: 0.9907\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0693 - acc: 0.9819 - val_loss: 0.0255 - val_acc: 0.9940\n",
      "====================================================\n",
      "=================Iteration  9 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=categorical_hinge, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 17s - loss: 1.0002 - acc: 0.0999 - val_loss: 1.0001 - val_acc: 0.0910\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.0001 - acc: 0.1010 - val_loss: 1.0002 - val_acc: 0.0983\n",
      "Epoch 3/10\n",
      " - 13s - loss: 1.0001 - acc: 0.1010 - val_loss: 1.0001 - val_acc: 0.0910\n",
      "Epoch 4/10\n",
      " - 13s - loss: 1.0001 - acc: 0.1006 - val_loss: 1.0002 - val_acc: 0.1062\n",
      "Epoch 5/10\n",
      " - 13s - loss: 1.0001 - acc: 0.0997 - val_loss: 1.0001 - val_acc: 0.0886\n",
      "Epoch 6/10\n",
      " - 13s - loss: 1.0001 - acc: 0.0997 - val_loss: 1.0001 - val_acc: 0.0960\n",
      "Epoch 7/10\n",
      " - 13s - loss: 1.0001 - acc: 0.1012 - val_loss: 1.0001 - val_acc: 0.0886\n",
      "Epoch 8/10\n",
      " - 13s - loss: 1.0001 - acc: 0.1006 - val_loss: 1.0001 - val_acc: 0.0974\n",
      "Epoch 9/10\n",
      " - 14s - loss: 1.0001 - acc: 0.0995 - val_loss: 1.0001 - val_acc: 0.1098\n",
      "Epoch 10/10\n",
      " - 14s - loss: 1.0001 - acc: 0.0990 - val_loss: 1.0001 - val_acc: 0.0960\n",
      "====================================================\n",
      "=================Iteration 10 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=categorical_hinge, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 15s - loss: 1.0002 - acc: 0.0998 - val_loss: 1.0001 - val_acc: 0.0995\n",
      "Epoch 2/10\n",
      " - 11s - loss: 1.0001 - acc: 0.0995 - val_loss: 1.0001 - val_acc: 0.0974\n",
      "Epoch 3/10\n",
      " - 11s - loss: 1.0001 - acc: 0.1006 - val_loss: 1.0002 - val_acc: 0.0886\n",
      "Epoch 4/10\n",
      " - 11s - loss: 1.0001 - acc: 0.1035 - val_loss: 1.0001 - val_acc: 0.0974\n",
      "Epoch 5/10\n",
      " - 11s - loss: 1.0001 - acc: 0.1009 - val_loss: 1.0001 - val_acc: 0.0979\n",
      "Epoch 6/10\n",
      " - 11s - loss: 1.0001 - acc: 0.1012 - val_loss: 1.0001 - val_acc: 0.0974\n",
      "Epoch 7/10\n",
      " - 11s - loss: 1.0001 - acc: 0.1003 - val_loss: 1.0001 - val_acc: 0.0886\n",
      "Epoch 8/10\n",
      " - 11s - loss: 1.0001 - acc: 0.0997 - val_loss: 1.0001 - val_acc: 0.0974\n",
      "Epoch 9/10\n",
      " - 11s - loss: 1.0001 - acc: 0.0989 - val_loss: 1.0001 - val_acc: 0.1062\n",
      "Epoch 10/10\n",
      " - 11s - loss: 1.0001 - acc: 0.0995 - val_loss: 1.0001 - val_acc: 0.0960\n",
      "====================================================\n",
      "=================Iteration 11 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=mean_squared_error, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 17s - loss: 0.0164 - acc: 0.8863 - val_loss: 0.0032 - val_acc: 0.9788\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.0065 - acc: 0.9580 - val_loss: 0.0023 - val_acc: 0.9862\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0054 - acc: 0.9662 - val_loss: 0.0022 - val_acc: 0.9869\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.0049 - acc: 0.9694 - val_loss: 0.0024 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0044 - acc: 0.9726 - val_loss: 0.0019 - val_acc: 0.9883\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0047 - acc: 0.9718 - val_loss: 0.0021 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0046 - acc: 0.9734 - val_loss: 0.0021 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.0051 - acc: 0.9715 - val_loss: 0.0023 - val_acc: 0.9879\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0053 - acc: 0.9718 - val_loss: 0.0020 - val_acc: 0.9893\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0052 - acc: 0.9723 - val_loss: 0.0022 - val_acc: 0.9886\n",
      "====================================================\n",
      "=================Iteration 12 of 18=================\n",
      "=================Training with optimizer=RMSProp, loss=mean_squared_error, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 15s - loss: 0.0181 - acc: 0.8731 - val_loss: 0.0039 - val_acc: 0.9740\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.0067 - acc: 0.9570 - val_loss: 0.0028 - val_acc: 0.9819\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0051 - acc: 0.9670 - val_loss: 0.0022 - val_acc: 0.9852\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0044 - acc: 0.9724 - val_loss: 0.0020 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0040 - acc: 0.9747 - val_loss: 0.0018 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0038 - acc: 0.9759 - val_loss: 0.0018 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0036 - acc: 0.9778 - val_loss: 0.0017 - val_acc: 0.9895\n",
      "Epoch 8/10\n",
      " - 12s - loss: 0.0033 - acc: 0.9793 - val_loss: 0.0018 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0033 - acc: 0.9799 - val_loss: 0.0015 - val_acc: 0.9907\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0031 - acc: 0.9812 - val_loss: 0.0015 - val_acc: 0.9914\n",
      "====================================================\n",
      "=================Iteration 13 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=categorical_crossentropy, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 17s - loss: 0.3761 - acc: 0.8842 - val_loss: 0.0653 - val_acc: 0.9790\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.1224 - acc: 0.9629 - val_loss: 0.0408 - val_acc: 0.9876\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0960 - acc: 0.9703 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.0820 - acc: 0.9756 - val_loss: 0.0325 - val_acc: 0.9902\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0740 - acc: 0.9778 - val_loss: 0.0294 - val_acc: 0.9917\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0647 - acc: 0.9803 - val_loss: 0.0281 - val_acc: 0.9924\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0636 - acc: 0.9806 - val_loss: 0.0258 - val_acc: 0.9933\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.0580 - acc: 0.9824 - val_loss: 0.0246 - val_acc: 0.9931\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0603 - acc: 0.9821 - val_loss: 0.0276 - val_acc: 0.9931\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0504 - acc: 0.9847 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "====================================================\n",
      "=================Iteration 14 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=categorical_crossentropy, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 15s - loss: 0.4622 - acc: 0.8550 - val_loss: 0.0650 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      " - 12s - loss: 0.1495 - acc: 0.9560 - val_loss: 0.0536 - val_acc: 0.9843\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.1155 - acc: 0.9650 - val_loss: 0.0459 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0988 - acc: 0.9714 - val_loss: 0.0338 - val_acc: 0.9888\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.0871 - acc: 0.9735 - val_loss: 0.0318 - val_acc: 0.9893\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0816 - acc: 0.9756 - val_loss: 0.0323 - val_acc: 0.9902\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0753 - acc: 0.9777 - val_loss: 0.0261 - val_acc: 0.9912\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0693 - acc: 0.9786 - val_loss: 0.0291 - val_acc: 0.9902\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0647 - acc: 0.9807 - val_loss: 0.0276 - val_acc: 0.9914\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0629 - acc: 0.9810 - val_loss: 0.0270 - val_acc: 0.9900\n",
      "====================================================\n",
      "=================Iteration 15 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=categorical_hinge, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 18s - loss: 1.0003 - acc: 0.1000 - val_loss: 1.0000 - val_acc: 0.1155\n",
      "Epoch 2/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1018 - val_loss: 1.0000 - val_acc: 0.0960\n",
      "Epoch 3/10\n",
      " - 13s - loss: 1.0000 - acc: 0.0999 - val_loss: 1.0000 - val_acc: 0.0974\n",
      "Epoch 4/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1002 - val_loss: 1.0000 - val_acc: 0.1062\n",
      "Epoch 5/10\n",
      " - 13s - loss: 1.0000 - acc: 0.0979 - val_loss: 1.0000 - val_acc: 0.1155\n",
      "Epoch 6/10\n",
      " - 14s - loss: 1.0000 - acc: 0.0997 - val_loss: 1.0000 - val_acc: 0.0983\n",
      "Epoch 7/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1010 - val_loss: 1.0000 - val_acc: 0.0974\n",
      "Epoch 8/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1014 - val_loss: 1.0000 - val_acc: 0.0974\n",
      "Epoch 9/10\n",
      " - 13s - loss: 1.0000 - acc: 0.1019 - val_loss: 1.0000 - val_acc: 0.0910\n",
      "Epoch 10/10\n",
      " - 13s - loss: 1.0000 - acc: 0.0995 - val_loss: 1.0000 - val_acc: 0.1062\n",
      "====================================================\n",
      "=================Iteration 16 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=categorical_hinge, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 16s - loss: 1.0002 - acc: 0.0990 - val_loss: 1.0001 - val_acc: 0.1062\n",
      "Epoch 2/10\n",
      " - 11s - loss: 1.0000 - acc: 0.0995 - val_loss: 1.0000 - val_acc: 0.1098\n",
      "Epoch 3/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1022 - val_loss: 1.0000 - val_acc: 0.0910\n",
      "Epoch 4/10\n",
      " - 11s - loss: 1.0000 - acc: 0.0999 - val_loss: 1.0000 - val_acc: 0.0910\n",
      "Epoch 5/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1000 - val_loss: 1.0000 - val_acc: 0.0886\n",
      "Epoch 6/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1012 - val_loss: 1.0000 - val_acc: 0.0886\n",
      "Epoch 7/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1028 - val_loss: 1.0000 - val_acc: 0.0974\n",
      "Epoch 8/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1006 - val_loss: 1.0000 - val_acc: 0.0910\n",
      "Epoch 9/10\n",
      " - 11s - loss: 1.0000 - acc: 0.0998 - val_loss: 1.0000 - val_acc: 0.0995\n",
      "Epoch 10/10\n",
      " - 11s - loss: 1.0000 - acc: 0.1050 - val_loss: 1.0000 - val_acc: 0.0983\n",
      "====================================================\n",
      "=================Iteration 17 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=mean_squared_error, epochs=10, batch_size=32================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 18s - loss: 0.0190 - acc: 0.8591 - val_loss: 0.0036 - val_acc: 0.9745\n",
      "Epoch 2/10\n",
      " - 13s - loss: 0.0064 - acc: 0.9587 - val_loss: 0.0037 - val_acc: 0.9764\n",
      "Epoch 3/10\n",
      " - 13s - loss: 0.0049 - acc: 0.9683 - val_loss: 0.0021 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      " - 13s - loss: 0.0042 - acc: 0.9733 - val_loss: 0.0022 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      " - 13s - loss: 0.0039 - acc: 0.9746 - val_loss: 0.0020 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      " - 13s - loss: 0.0035 - acc: 0.9786 - val_loss: 0.0016 - val_acc: 0.9902\n",
      "Epoch 7/10\n",
      " - 13s - loss: 0.0032 - acc: 0.9793 - val_loss: 0.0014 - val_acc: 0.9910\n",
      "Epoch 8/10\n",
      " - 13s - loss: 0.0030 - acc: 0.9805 - val_loss: 0.0016 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0028 - acc: 0.9818 - val_loss: 0.0013 - val_acc: 0.9917\n",
      "Epoch 10/10\n",
      " - 13s - loss: 0.0027 - acc: 0.9827 - val_loss: 0.0011 - val_acc: 0.9933\n",
      "====================================================\n",
      "=================Iteration 18 of 18=================\n",
      "=================Training with optimizer=Adagrad, loss=mean_squared_error, epochs=10, batch_size=64================\n",
      "====================================================\n",
      "Epoch 1/10\n",
      " - 16s - loss: 0.0182 - acc: 0.8715 - val_loss: 0.0037 - val_acc: 0.9760\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.0063 - acc: 0.9591 - val_loss: 0.0025 - val_acc: 0.9840\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.0051 - acc: 0.9674 - val_loss: 0.0022 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.0043 - acc: 0.9716 - val_loss: 0.0020 - val_acc: 0.9876\n",
      "Epoch 5/10\n",
      " - 12s - loss: 0.0038 - acc: 0.9757 - val_loss: 0.0015 - val_acc: 0.9895\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.0036 - acc: 0.9774 - val_loss: 0.0015 - val_acc: 0.9905\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.0033 - acc: 0.9792 - val_loss: 0.0015 - val_acc: 0.9905\n",
      "Epoch 8/10\n",
      " - 11s - loss: 0.0030 - acc: 0.9801 - val_loss: 0.0017 - val_acc: 0.9888\n",
      "Epoch 9/10\n",
      " - 11s - loss: 0.0029 - acc: 0.9813 - val_loss: 0.0013 - val_acc: 0.9919\n",
      "Epoch 10/10\n",
      " - 11s - loss: 0.0029 - acc: 0.9813 - val_loss: 0.0012 - val_acc: 0.9931\n",
      "=================Done!=================\n",
      "Best model: optimizer=RMSProp, loss=categorical_crossentropy, epochs=10, batch_size=64, val_acc=0.994048\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score = 0\n",
    "best_optimizer = None\n",
    "best_loss = 0\n",
    "best_epochs = 0\n",
    "best_batch_size = 0\n",
    "hyperparameters = list(itertools.product(optimizers,losses, batch_sizes))\n",
    "i = 0\n",
    "for optimizer, loss, batch_size in hyperparameters:\n",
    "    i += 1\n",
    "    print('====================================================')\n",
    "    print('=================Iteration %2d of %d=================' % (i , len(hyperparameters)))\n",
    "    print('=================Training with optimizer=%s, loss=%s, epochs=%d, batch_size=%d================' % (optimizer, loss, epochs, batch_size))\n",
    "    print('====================================================')\n",
    "    model, score = train_model(X_train, Y_train, X_val, Y_val, optimizer, loss, epochs, batch_size)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_optimizer = optimizer\n",
    "        best_loss = loss\n",
    "        best_epochs = epochs\n",
    "        best_batch_size = batch_size\n",
    "\n",
    "print('=======================================')\n",
    "print('=================Done!=================')\n",
    "print('Best model: optimizer=%s, loss=%s, epochs=%d, batch_size=%d, val_acc=%f' % (best_optimizer, best_loss, best_epochs, best_batch_size, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "===============Training with optimizer=RMSProp, loss=categorical_crossentropy, epochs=20, batch_size=64==============\n",
      "====================================================\n",
      "Epoch 1/20\n",
      " - 16s - loss: 0.3738 - acc: 0.8797 - val_loss: 0.0664 - val_acc: 0.9800\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1194 - acc: 0.9650 - val_loss: 0.0535 - val_acc: 0.9850\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0907 - acc: 0.9732 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.0832 - acc: 0.9762 - val_loss: 0.0356 - val_acc: 0.9876\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0771 - acc: 0.9785 - val_loss: 0.0256 - val_acc: 0.9929\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0717 - acc: 0.9796 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0683 - acc: 0.9813 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0679 - acc: 0.9808 - val_loss: 0.0278 - val_acc: 0.9921\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0700 - acc: 0.9799 - val_loss: 0.0426 - val_acc: 0.9886\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0691 - acc: 0.9819 - val_loss: 0.0299 - val_acc: 0.9921\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0702 - acc: 0.9813 - val_loss: 0.0290 - val_acc: 0.9905\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0716 - acc: 0.9808 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0703 - acc: 0.9817 - val_loss: 0.0287 - val_acc: 0.9933\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0739 - acc: 0.9814 - val_loss: 0.0349 - val_acc: 0.9895\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0754 - acc: 0.9803 - val_loss: 0.0384 - val_acc: 0.9879\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0724 - acc: 0.9816 - val_loss: 0.0584 - val_acc: 0.9864\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0773 - acc: 0.9803 - val_loss: 0.0580 - val_acc: 0.9914\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0775 - acc: 0.9810 - val_loss: 0.0434 - val_acc: 0.9917\n",
      "Epoch 19/20\n",
      " - 12s - loss: 0.0809 - acc: 0.9807 - val_loss: 0.0460 - val_acc: 0.9910\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0835 - acc: 0.9797 - val_loss: 0.0392 - val_acc: 0.9900\n",
      "Best model retrained: optimizer=RMSProp, loss=categorical_crossentropy, epochs=20, batch_size=64, val_acc=0.990000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "print('====================================================')\n",
    "print('===============Training with optimizer=%s, loss=%s, epochs=%d, batch_size=%d==============' % (best_optimizer, best_loss, epochs, best_batch_size))\n",
    "print('====================================================')\n",
    "model, score = train_model(X_train, Y_train, X_val, Y_val, best_optimizer, best_loss, epochs, best_batch_size)\n",
    "print('Best model retrained: optimizer=%s, loss=%s, epochs=%d, batch_size=%d, val_acc=%f' % (best_optimizer, best_loss, epochs, best_batch_size, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
